{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dcc55a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "connections = pd.read_csv(\"Data/Walking Distances Gate-to-Gate.csv\")\n",
    "\n",
    "pair_dists = connections.to_numpy().astype(np.float64)\n",
    "\n",
    "# Handle NaNs or missing values if any\n",
    "pair_dists = np.nan_to_num(pair_dists, nan=np.inf)  # or set to large value\n",
    "\n",
    "# Min-max normalization (excluding infinities)\n",
    "finite_vals = pair_dists[np.isfinite(pair_dists)]\n",
    "min_val = np.min(finite_vals)\n",
    "max_val = np.max(finite_vals)\n",
    "\n",
    "normalized_dists = (pair_dists - min_val) / (max_val - min_val)\n",
    "normalized_dists[~np.isfinite(pair_dists)] = 1.0  # keep inf as 1 (furthest apart)\n",
    "\n",
    "pair_dists = normalized_dists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18e37c",
   "metadata": {},
   "source": [
    "# Code to construct clustered medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "76401933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster assignments: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "Medoid indices: [44 33  7 19 74 28 59 88]\n",
      "MSE loss of medoid approximation: 0.003475906038024968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "def k_medoids_single_run(pair_dists, k, max_iter=300):\n",
    "    n = pair_dists.shape[0]\n",
    "    curr_medoids = np.random.choice(n, k, replace=False)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        labels = np.argmin(pair_dists[:, curr_medoids], axis=1)\n",
    "        new_medoids = np.copy(curr_medoids)\n",
    "\n",
    "        for cluster_id in range(k):\n",
    "            cluster_points = np.where(labels == cluster_id)[0]\n",
    "            if len(cluster_points) == 0:\n",
    "                continue\n",
    "            intra_cluster_dists = pair_dists[np.ix_(cluster_points, cluster_points)]\n",
    "            total_dists = np.sum(intra_cluster_dists, axis=1)\n",
    "            new_medoids[cluster_id] = cluster_points[np.argmin(total_dists)]\n",
    "\n",
    "        if np.all(curr_medoids == new_medoids):\n",
    "            break\n",
    "        curr_medoids = new_medoids\n",
    "\n",
    "    final_labels = np.argmin(pair_dists[:, curr_medoids], axis=1)\n",
    "    return final_labels, curr_medoids\n",
    "\n",
    "def compute_medoids_mse(pair_dists, labels, medoids):\n",
    "    medoid_map = np.array(medoids)[labels]\n",
    "    approx_dists = pair_dists[np.ix_(medoid_map, medoid_map)]\n",
    "    mse = np.mean((pair_dists - approx_dists) ** 2)\n",
    "    return mse\n",
    "\n",
    "def k_medoids(pair_dists, k, max_iter=300, n_init=1000, verbose=False):\n",
    "    best_loss = float(\"inf\")\n",
    "    best_labels, best_medoids = None, None\n",
    "\n",
    "    for i in range(n_init):\n",
    "        labels, medoids = k_medoids_single_run(pair_dists, k, max_iter)\n",
    "        mse_loss = compute_medoids_mse(pair_dists, labels, medoids)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[Run {i+1}] MSE Loss: {mse_loss:.6f}\")\n",
    "\n",
    "        if mse_loss < best_loss:\n",
    "            best_loss = mse_loss\n",
    "            best_labels = labels\n",
    "            best_medoids = medoids\n",
    "\n",
    "    return best_labels, best_medoids\n",
    "\n",
    "\n",
    "\n",
    "labels, medoids = k_medoids(pair_dists, k=8)\n",
    "print(\"Cluster assignments:\", labels)\n",
    "print(\"Medoid indices:\", medoids)\n",
    "\n",
    "mse_loss = compute_medoids_mse(pair_dists, labels, medoids)\n",
    "print(\"MSE loss of medoid approximation:\", mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "56a9c320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise distance matrix between medoids:\n",
      "[[0.         0.11133768 0.44616639 0.46615008 0.64274062 0.24347471\n",
      "  0.1358075  0.77773246]\n",
      " [0.11133768 0.         0.55750408 0.3817292  0.55831974 0.13213703\n",
      "  0.24714519 0.69331158]\n",
      " [0.44616639 0.55750408 0.         0.18107667 0.40334421 0.68964111\n",
      "  0.4233279  0.53874388]\n",
      " [0.46615008 0.3817292  0.18107667 0.         0.25774878 0.51386623\n",
      "  0.58360522 0.39314845]\n",
      " [0.64274062 0.55831974 0.40334421 0.25774878 0.         0.69045677\n",
      "  0.73001631 0.1680261 ]\n",
      " [0.24347471 0.13213703 0.68964111 0.51386623 0.69045677 0.\n",
      "  0.37928222 0.82544861]\n",
      " [0.1358075  0.24714519 0.4233279  0.58360522 0.73001631 0.37928222\n",
      "  0.         0.86541599]\n",
      " [0.77773246 0.69331158 0.53874388 0.39314845 0.1680261  0.82544861\n",
      "  0.86541599 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_medoid_distance_matrix(pair_dists, medoids):\n",
    "    \"\"\"\n",
    "    Returns the pairwise distance matrix between medoids.\n",
    "\n",
    "    Args:\n",
    "        pair_dists (np.ndarray): Full NxN pairwise distance matrix.\n",
    "        medoids (list or np.ndarray): List of indices of medoid points.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: KxK distance matrix between medoids.\n",
    "    \"\"\"\n",
    "    medoids = np.array(medoids)\n",
    "    return pair_dists[np.ix_(medoids, medoids)]\n",
    "\n",
    "pair_dists_medoid = get_medoid_distance_matrix(pair_dists, medoids)\n",
    "\n",
    "print(\"Pairwise distance matrix between medoids:\")\n",
    "print(pair_dists_medoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2407165",
   "metadata": {},
   "source": [
    "# Function to linearize given set of pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3c099c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "def optimize_1T_E_minus_1T_S(pair_dists, d=2, num_iters=10000, lr=1e-2, verbose=True):\n",
    "    \"\"\"\n",
    "    Optimize E and S to minimize sum((1^T E_i - 1^T S_j - pair_dists[i,j])^2)\n",
    "    \n",
    "    pair_dists: torch.Tensor of shape (k, k)\n",
    "    d: dimensionality of E and S\n",
    "    \"\"\"\n",
    "    k = pair_dists.shape[0]\n",
    "    \n",
    "    # E and S are k x d matrices\n",
    "    E = torch.randn((k, d), requires_grad=True)\n",
    "    S = torch.randn((k, d), requires_grad=True)\n",
    "    \n",
    "    optimizer = optim.Adam([E, S], lr=lr)\n",
    "    \n",
    "    for iter in range(num_iters):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 1^T E_i = sum over dim-1 (axis=1) â†’ shape (k,)\n",
    "        E_sum = E.sum(dim=1)  # shape (k,)\n",
    "        S_sum = S.sum(dim=1)  # shape (k,)\n",
    "\n",
    "        # Compute outer difference: E_sum[i] - S_sum[j]\n",
    "        # Assume E_sum and S_sum are 1D tensors of shape (k,)\n",
    "        E_sum = E_sum.view(-1, 1)  # Shape: (k, 1)\n",
    "        S_sum = S_sum.view(1, -1)  # Shape: (1, k)\n",
    "\n",
    "        diff_matrix = E_sum - S_sum  # Shape: (k, k)\n",
    "        torch.diagonal(diff_matrix).zero_()  # Set diagonal to 0 in-place\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        loss = ((diff_matrix - pair_dists) ** 2).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if verbose and iter % 100 == 0:\n",
    "            print(f\"Iter {iter}: Loss = {loss.item():.6f}\")\n",
    "    \n",
    "    return E.detach(), S.detach(), loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4554bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: Loss = 1512624.500000\n",
      "Iter 100: Loss = 672101.312500\n",
      "Iter 200: Loss = 424409.937500\n",
      "Iter 300: Loss = 371110.500000\n",
      "Iter 400: Loss = 358178.375000\n",
      "Iter 500: Loss = 354126.125000\n",
      "Iter 600: Loss = 352831.750000\n",
      "Iter 700: Loss = 352447.812500\n",
      "Iter 800: Loss = 352343.843750\n",
      "Iter 900: Loss = 352318.437500\n",
      "Iter 1000: Loss = 352312.875000\n",
      "Iter 1100: Loss = 352311.781250\n",
      "Iter 1200: Loss = 352311.625000\n",
      "Iter 1300: Loss = 352311.593750\n",
      "Iter 1400: Loss = 352311.593750\n",
      "Iter 1500: Loss = 352311.562500\n",
      "Iter 1600: Loss = 352311.562500\n",
      "Iter 1700: Loss = 352311.593750\n",
      "Iter 1800: Loss = 352311.593750\n",
      "Iter 1900: Loss = 352311.593750\n",
      "Iter 2000: Loss = 352311.593750\n",
      "Iter 2100: Loss = 352311.593750\n",
      "Iter 2200: Loss = 352311.593750\n",
      "Iter 2300: Loss = 352311.593750\n",
      "Iter 2400: Loss = 352311.593750\n",
      "Iter 2500: Loss = 352311.593750\n",
      "Iter 2600: Loss = 352311.593750\n",
      "Iter 2700: Loss = 352311.593750\n",
      "Iter 2800: Loss = 352311.593750\n",
      "Iter 2900: Loss = 352311.562500\n",
      "Iter 3000: Loss = 352311.562500\n",
      "Iter 3100: Loss = 352311.562500\n",
      "Iter 3200: Loss = 352311.593750\n",
      "Iter 3300: Loss = 352311.593750\n",
      "Iter 3400: Loss = 352311.593750\n",
      "Iter 3500: Loss = 352311.593750\n",
      "Iter 3600: Loss = 352311.593750\n",
      "Iter 3700: Loss = 352311.593750\n",
      "Iter 3800: Loss = 352311.593750\n",
      "Iter 3900: Loss = 352311.593750\n",
      "Iter 4000: Loss = 352311.593750\n",
      "Iter 4100: Loss = 352311.593750\n",
      "Iter 4200: Loss = 352311.562500\n",
      "Iter 4300: Loss = 352311.593750\n",
      "Iter 4400: Loss = 352311.593750\n",
      "Iter 4500: Loss = 352311.593750\n",
      "Iter 4600: Loss = 352311.593750\n",
      "Iter 4700: Loss = 352311.593750\n",
      "Iter 4800: Loss = 352311.593750\n",
      "Iter 4900: Loss = 352311.562500\n",
      "Iter 5000: Loss = 352311.562500\n",
      "Iter 5100: Loss = 352311.562500\n",
      "Iter 5200: Loss = 352311.562500\n",
      "Iter 5300: Loss = 352311.562500\n",
      "Iter 5400: Loss = 352311.562500\n",
      "Iter 5500: Loss = 352311.562500\n",
      "Iter 5600: Loss = 352311.562500\n",
      "Iter 5700: Loss = 352311.593750\n",
      "Iter 5800: Loss = 352311.562500\n",
      "Iter 5900: Loss = 352311.562500\n",
      "Iter 6000: Loss = 352311.562500\n",
      "Iter 6100: Loss = 352311.562500\n",
      "Iter 6200: Loss = 352311.593750\n",
      "Iter 6300: Loss = 352311.562500\n",
      "Iter 6400: Loss = 352311.593750\n",
      "Iter 6500: Loss = 352311.593750\n",
      "Iter 6600: Loss = 352311.593750\n",
      "Iter 6700: Loss = 352311.593750\n",
      "Iter 6800: Loss = 352311.562500\n",
      "Iter 6900: Loss = 352311.562500\n",
      "Iter 7000: Loss = 352311.562500\n",
      "Iter 7100: Loss = 352311.562500\n",
      "Iter 7200: Loss = 352311.562500\n",
      "Iter 7300: Loss = 352311.562500\n",
      "Iter 7400: Loss = 352311.593750\n",
      "Iter 7500: Loss = 352311.593750\n",
      "Iter 7600: Loss = 352311.562500\n",
      "Iter 7700: Loss = 352311.593750\n",
      "Iter 7800: Loss = 352311.562500\n",
      "Iter 7900: Loss = 352311.562500\n",
      "Iter 8000: Loss = 352311.593750\n",
      "Iter 8100: Loss = 352311.593750\n",
      "Iter 8200: Loss = 352311.562500\n",
      "Iter 8300: Loss = 352311.562500\n",
      "Iter 8400: Loss = 352311.593750\n",
      "Iter 8500: Loss = 352311.593750\n",
      "Iter 8600: Loss = 352311.562500\n",
      "Iter 8700: Loss = 352311.593750\n",
      "Iter 8800: Loss = 352311.593750\n",
      "Iter 8900: Loss = 352311.593750\n",
      "Iter 9000: Loss = 352311.593750\n",
      "Iter 9100: Loss = 352311.593750\n",
      "Iter 9200: Loss = 352311.562500\n",
      "Iter 9300: Loss = 352311.593750\n",
      "Iter 9400: Loss = 352311.562500\n",
      "Iter 9500: Loss = 352311.562500\n",
      "Iter 9600: Loss = 352311.593750\n",
      "Iter 9700: Loss = 352311.593750\n",
      "Iter 9800: Loss = 352311.593750\n",
      "Iter 9900: Loss = 352311.593750\n",
      "Recovered E sums: tensor([689.7102, 613.7101, 564.7740, 536.0506, 463.9655, 450.2421, 439.5187,\n",
      "        426.4336, 402.3271, 397.5612, 393.1995, 388.7740, 379.0293, 374.0719,\n",
      "        368.5613, 363.6251, 352.5399, 340.9442, 340.2846, 346.5825, 296.5612,\n",
      "        295.7953, 312.6464, 354.7740, 362.6038, 406.6038, 764.3698, 742.3698,\n",
      "        714.9655, 564.6463, 524.3910, 497.8591, 480.8804, 414.5825, 414.5825,\n",
      "        403.7953, 387.6251, 397.9016, 401.8166, 404.7527, 410.5400, 415.3059,\n",
      "        418.9016, 425.9442, 429.5187, 437.7527, 441.2421, 441.8804, 446.3272,\n",
      "        478.7102, 546.2421, 543.8165, 546.4761, 541.7847, 539.4442, 539.2314,\n",
      "        534.8059, 534.9761, 534.9761, 534.6570, 544.2634, 530.2634, 542.4761,\n",
      "        577.1995, 608.0931, 629.1570, 652.6463, 652.6464, 525.7208, 555.5506,\n",
      "        551.8378, 527.4655, 523.0187, 528.3378, 508.4016, 495.3166, 491.5719,\n",
      "        516.8698, 519.4229, 548.4442, 583.1676, 583.1677, 620.0612, 620.0612,\n",
      "        659.1251, 692.1890, 699.5506, 737.3378, 743.2953, 758.1251, 770.6357,\n",
      "        830.7421, 867.2527, 901.7208, 942.8272, 963.8272])\n",
      "Recovered S sums: tensor([-695.9574, -619.9574, -571.0212, -542.2979, -470.2128, -456.4894,\n",
      "        -445.7660, -432.6809, -408.5745, -403.8085, -399.4468, -395.0213,\n",
      "        -385.2766, -380.3192, -374.8085, -369.8724, -358.7873, -347.1915,\n",
      "        -346.5319, -352.8298, -302.8085, -302.0426, -318.8936, -361.0213,\n",
      "        -368.8511, -412.8511, -770.6170, -748.6170, -721.2128, -570.8936,\n",
      "        -530.6383, -504.1064, -487.1277, -420.8298, -420.8298, -410.0426,\n",
      "        -393.8723, -404.1490, -408.0638, -411.0000, -416.7873, -421.5532,\n",
      "        -425.1490, -432.1915, -435.7660, -444.0000, -447.4894, -448.1277,\n",
      "        -452.5745, -484.9575, -552.4894, -550.0638, -552.7234, -548.0319,\n",
      "        -545.6915, -545.4787, -541.0532, -541.2234, -541.2234, -540.9043,\n",
      "        -550.5107, -536.5107, -548.7234, -583.4468, -614.3405, -635.4043,\n",
      "        -658.8937, -658.8937, -531.9681, -561.7979, -558.0851, -533.7128,\n",
      "        -529.2660, -534.5851, -514.6489, -501.5638, -497.8192, -523.1171,\n",
      "        -525.6702, -554.6915, -589.4149, -589.4150, -626.3085, -626.3085,\n",
      "        -665.3724, -698.4362, -705.7979, -743.5851, -749.5425, -764.3724,\n",
      "        -776.8830, -836.9894, -873.5000, -907.9681, -949.0744, -970.0745])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "    d = 300\n",
    "\n",
    "\n",
    "    pair_dists_torch = torch.tensor(pair_dists, dtype=torch.float32)\n",
    "        \n",
    "    # Optimize to recover E and S\n",
    "    E_opt, S_opt, loss = optimize_1T_E_minus_1T_S(pair_dists_torch, d=d)\n",
    "    print(\"Recovered E sums:\", E_opt.sum(dim=1))\n",
    "    print(\"Recovered S sums:\", S_opt.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75152a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: Loss = 1049612.500000\n",
      "Iter 100: Loss = 363635.281250\n",
      "Iter 200: Loss = 156164.828125\n",
      "Iter 300: Loss = 105699.367188\n",
      "Iter 400: Loss = 90272.390625\n",
      "Iter 500: Loss = 84586.093750\n",
      "Iter 600: Loss = 82594.687500\n",
      "Iter 700: Loss = 81969.656250\n",
      "Iter 800: Loss = 81795.125000\n",
      "Iter 900: Loss = 81751.984375\n",
      "Iter 1000: Loss = 81742.578125\n",
      "Iter 1100: Loss = 81740.773438\n",
      "Iter 1200: Loss = 81740.468750\n",
      "Iter 1300: Loss = 81740.421875\n",
      "Iter 1400: Loss = 81740.414062\n",
      "Iter 1500: Loss = 81740.406250\n",
      "Iter 1600: Loss = 81740.406250\n",
      "Iter 1700: Loss = 81740.414062\n",
      "Iter 1800: Loss = 81740.406250\n",
      "Iter 1900: Loss = 81740.421875\n",
      "Iter 2000: Loss = 81740.414062\n",
      "Iter 2100: Loss = 81740.414062\n",
      "Iter 2200: Loss = 81740.421875\n",
      "Iter 2300: Loss = 81740.406250\n",
      "Iter 2400: Loss = 81740.406250\n",
      "Iter 2500: Loss = 81740.406250\n",
      "Iter 2600: Loss = 81740.406250\n",
      "Iter 2700: Loss = 81740.406250\n",
      "Iter 2800: Loss = 81740.406250\n",
      "Iter 2900: Loss = 81740.414062\n",
      "Iter 3000: Loss = 81740.406250\n",
      "Iter 3100: Loss = 81740.406250\n",
      "Iter 3200: Loss = 81740.414062\n",
      "Iter 3300: Loss = 81740.421875\n",
      "Iter 3400: Loss = 81740.406250\n",
      "Iter 3500: Loss = 81740.421875\n",
      "Iter 3600: Loss = 81740.406250\n",
      "Iter 3700: Loss = 81740.406250\n",
      "Iter 3800: Loss = 81740.406250\n",
      "Iter 3900: Loss = 81740.406250\n",
      "Iter 4000: Loss = 81740.406250\n",
      "Iter 4100: Loss = 81740.406250\n",
      "Iter 4200: Loss = 81740.406250\n",
      "Iter 4300: Loss = 81740.406250\n",
      "Iter 4400: Loss = 81740.406250\n",
      "Iter 4500: Loss = 81740.406250\n",
      "Iter 4600: Loss = 81740.406250\n",
      "Iter 4700: Loss = 81740.406250\n",
      "Iter 4800: Loss = 81740.406250\n",
      "Iter 4900: Loss = 81740.406250\n",
      "Iter 5000: Loss = 81740.406250\n",
      "Iter 5100: Loss = 81740.406250\n",
      "Iter 5200: Loss = 81740.421875\n",
      "Iter 5300: Loss = 81740.414062\n",
      "Iter 5400: Loss = 81740.406250\n",
      "Iter 5500: Loss = 81740.406250\n",
      "Iter 5600: Loss = 81740.406250\n",
      "Iter 5700: Loss = 81740.406250\n",
      "Iter 5800: Loss = 81740.421875\n",
      "Iter 5900: Loss = 81740.406250\n",
      "Iter 6000: Loss = 81740.421875\n",
      "Iter 6100: Loss = 81740.406250\n",
      "Iter 6200: Loss = 81740.421875\n",
      "Iter 6300: Loss = 81740.421875\n",
      "Iter 6400: Loss = 81740.406250\n",
      "Iter 6500: Loss = 81740.406250\n",
      "Iter 6600: Loss = 81740.406250\n",
      "Iter 6700: Loss = 81740.421875\n",
      "Iter 6800: Loss = 81740.406250\n",
      "Iter 6900: Loss = 81740.406250\n",
      "Iter 7000: Loss = 81740.406250\n",
      "Iter 7100: Loss = 81740.414062\n",
      "Iter 7200: Loss = 81740.421875\n",
      "Iter 7300: Loss = 81740.406250\n",
      "Iter 7400: Loss = 81740.406250\n",
      "Iter 7500: Loss = 81740.406250\n",
      "Iter 7600: Loss = 81740.406250\n",
      "Iter 7700: Loss = 81740.406250\n",
      "Iter 7800: Loss = 81740.406250\n",
      "Iter 7900: Loss = 81740.406250\n",
      "Iter 8000: Loss = 81740.421875\n",
      "Iter 8100: Loss = 81740.421875\n",
      "Iter 8200: Loss = 81740.406250\n",
      "Iter 8300: Loss = 81740.406250\n",
      "Iter 8400: Loss = 81740.421875\n",
      "Iter 8500: Loss = 81740.421875\n",
      "Iter 8600: Loss = 81740.421875\n",
      "Iter 8700: Loss = 81740.421875\n",
      "Iter 8800: Loss = 81740.421875\n",
      "Iter 8900: Loss = 81740.421875\n",
      "Iter 9000: Loss = 81740.421875\n",
      "Iter 9100: Loss = 81740.421875\n",
      "Iter 9200: Loss = 81740.421875\n",
      "Iter 9300: Loss = 81740.421875\n",
      "Iter 9400: Loss = 81740.421875\n",
      "Iter 9500: Loss = 81740.414062\n",
      "Iter 9600: Loss = 81740.421875\n",
      "Iter 9700: Loss = 81740.414062\n",
      "Iter 9800: Loss = 81740.421875\n",
      "Iter 9900: Loss = 81740.421875\n",
      "Recovered E sums: tensor([835.7474, 460.7475, 713.0808, 224.0808, 488.4141])\n",
      "Recovered S sums: tensor([-837.4192, -462.4192, -714.7526, -225.7526, -490.0858])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "    d = 300\n",
    "\n",
    "\n",
    "    pair_dists_medoid_torch = torch.tensor(pair_dists_medoid, dtype=torch.float32)\n",
    "        \n",
    "    # Optimize to recover E and S\n",
    "    E_opt, S_opt, loss = optimize_1T_E_minus_1T_S(pair_dists_medoid_torch, d=d)\n",
    "    print(\"Recovered E sums:\", E_opt.sum(dim=1))\n",
    "    print(\"Recovered S sums:\", S_opt.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a2f57",
   "metadata": {},
   "source": [
    "# Find optimal clustering level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f9ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running k-medoids with k = 2\n",
      "MSE loss of medoid approximation: 0.05348684069657175\n",
      "MSE of linear approximation for k=2: 0.000191\n",
      "Total loss for k=2: 0.053678\n",
      "Running k-medoids with k = 3\n",
      "MSE loss of medoid approximation: 0.018155348208648465\n",
      "MSE of linear approximation for k=3: 0.000001\n",
      "Total loss for k=3: 0.018157\n",
      "Running k-medoids with k = 4\n",
      "MSE loss of medoid approximation: 0.012529314906599587\n",
      "MSE of linear approximation for k=4: 0.013836\n",
      "Total loss for k=4: 0.026365\n",
      "Running k-medoids with k = 5\n",
      "MSE loss of medoid approximation: 0.00878513612604761\n",
      "MSE of linear approximation for k=5: 0.027981\n",
      "Total loss for k=5: 0.036767\n",
      "Running k-medoids with k = 6\n",
      "MSE loss of medoid approximation: 0.005968844849765581\n",
      "MSE of linear approximation for k=6: 0.022353\n",
      "Total loss for k=6: 0.028322\n",
      "Running k-medoids with k = 7\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "medoid_vals = list(range(2, 20))\n",
    "medoid_approx_losses = []\n",
    "linear_reconstruction_losses = []\n",
    "total_losses = []\n",
    "\n",
    "min_num_medoid = -1\n",
    "min_medoid_loss = float(\"inf\")\n",
    "\n",
    "for k in medoid_vals:\n",
    "    print(\"Running k-medoids with k =\", k)\n",
    "\n",
    "    labels, medoids = k_medoids(pair_dists, k=k)\n",
    "    mse_loss = compute_medoids_mse(pair_dists, labels, medoids)\n",
    "    print(\"MSE loss of medoid approximation:\", mse_loss)\n",
    "\n",
    "    pair_dists_medoid = get_medoid_distance_matrix(pair_dists, medoids)\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    d = 300\n",
    "    pair_dists_medoid_torch = torch.tensor(pair_dists_medoid, dtype=torch.float32)\n",
    "\n",
    "    # Optimize to recover E and S\n",
    "    E_opt, S_opt, loss = optimize_1T_E_minus_1T_S(pair_dists_medoid_torch, d=d, verbose=False)\n",
    "    print(f\"MSE of linear approximation for k={k}: {loss:.6f}\")\n",
    "\n",
    "    total_loss = mse_loss + loss\n",
    "    print(f\"Total loss for k={k}: {total_loss:.6f}\")\n",
    "\n",
    "    # Save all losses\n",
    "    medoid_approx_losses.append(mse_loss)\n",
    "    linear_reconstruction_losses.append(loss)\n",
    "    total_losses.append(total_loss)\n",
    "\n",
    "    if total_loss < min_medoid_loss:\n",
    "        min_medoid_loss = total_loss\n",
    "        min_num_medoid = k\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(medoid_vals, medoid_approx_losses, label='Medoid Approx. MSE')\n",
    "plt.plot(medoid_vals, linear_reconstruction_losses, label='Linear Recon. MSE')\n",
    "plt.plot(medoid_vals, total_losses, label='Total Loss', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.xlabel('Number of Medoids (k)')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Number of Medoids')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMinimum total loss {min_medoid_loss:.6f} at k={min_num_medoid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d70033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
